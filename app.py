# app.py

import streamlit as st
import os
import re
from datetime import datetime
from glob import glob

from src.writer_agent import WriterAgent
from src.doc_gen import DocumentGenerator

st.set_page_config(page_title="AI æ·±åº¦å†™ä½œç³»ç»Ÿ", page_icon="ğŸ“", layout="wide")

BASE_OUTPUT_DIR = "./output"
BASE_DATA_DIR = "./data/uploads"

def render_article_preview(markdown_text, image_base_dir):
    parts = re.split(r'(\!\[.*?\]\(.*?\))', markdown_text)
    for part in parts:
        img_match = re.match(r'\!\[(.*?)\]\((.*?)\)', part)
        if img_match:
            alt_text = img_match.group(1)
            raw_path = img_match.group(2)
            possible_paths = [
                raw_path,
                os.path.join(image_base_dir, raw_path),
                os.path.join(image_base_dir, "assets", os.path.basename(raw_path))
            ]
            found_img = None
            for p in possible_paths:
                p = p.replace("/", os.sep).replace("\\", os.sep)
                if os.path.exists(p):
                    found_img = p
                    break
            if found_img:
                st.image(found_img, caption=alt_text)
            else:
                st.warning(f"âš ï¸ å›¾ç‰‡ä¸¢å¤±: {raw_path}")
        else:
            if part.strip():
                st.markdown(part)

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ä¸»ç¼–ã€‚è¯·è¾“å…¥ä¸»é¢˜ï¼Œæˆ‘å°†å…ˆæ£€ç´¢å…¨ç½‘ä¿¡æ¯ï¼Œå†ä¸ºæ‚¨å†™ä½œã€‚"}]
if "processing" not in st.session_state:
    st.session_state.processing = False

with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶å°")
    uploaded_files = st.file_uploader("ğŸ“‚ ä¸Šä¼  RAG èµ„æ–™", accept_multiple_files=True)
    current_data_dir = None
    if uploaded_files:
        session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        current_data_dir = os.path.join(BASE_DATA_DIR, session_id)
        os.makedirs(current_data_dir, exist_ok=True)
        for f in uploaded_files:
            with open(os.path.join(current_data_dir, f.name), "wb") as w:
                w.write(f.getbuffer())
        st.success(f"âœ… å·²æŒ‚è½½ {len(uploaded_files)} ä»½èµ„æ–™")
    st.divider()
    if os.path.exists(BASE_OUTPUT_DIR):
        tasks = sorted([d for d in os.listdir(BASE_OUTPUT_DIR) if os.path.isdir(os.path.join(BASE_OUTPUT_DIR, d))], reverse=True)
        selected_task = st.selectbox("æŸ¥çœ‹æ—§æ–‡", ["-- é€‰æ‹©ä»»åŠ¡ --"] + tasks)
        if selected_task and selected_task != "-- é€‰æ‹©ä»»åŠ¡ --":
            task_path = os.path.join(BASE_OUTPUT_DIR, selected_task)
            md_files = glob(os.path.join(task_path, "*.md"))
            if md_files:
                with open(md_files[0], "r", encoding="utf-8") as f:
                    content = f.read()
                if st.button("ğŸ“– åœ¨çº¿é˜…è¯»"):
                    render_article_preview(content, task_path)

st.title("ğŸ“ Agentic Writer Pro")
st.caption("Mixed Retrieval | Auto-Correction | Source Citation")

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("è¾“å…¥æ–‡ç« ä¸»é¢˜...", disabled=st.session_state.processing):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.processing = True
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_topic = "".join([c for c in prompt if c.isalnum()])[:15]
    task_dir = os.path.join(BASE_OUTPUT_DIR, f"{timestamp}_{safe_topic}")
    os.makedirs(task_dir, exist_ok=True)

    with st.chat_message("assistant"):
        st.markdown(f"æ”¶åˆ°ä¸»é¢˜ **â€œ{prompt}â€**ï¼Œå·¥ä½œæµå¯åŠ¨...")
        
        with st.status("ğŸš€ è¿è¡Œä¸­...", expanded=True) as status:
            agent = WriterAgent(output_dir=task_dir)
            
            # Step 1
            if current_data_dir:
                status.write(f"ğŸ“š æ­£åœ¨å‘é‡åŒ– {len(uploaded_files)} ä»½æ–‡æ¡£...")
                agent.rag.ingest_data(current_data_dir)
            
            # Step 2
            status.write("ğŸ§  æ­£åœ¨è§„åˆ’å¤§çº² ...")
            outline = agent.plan_outline(prompt)
            
            if not outline:
                status.update(label="âŒ å¤§çº²ç”Ÿæˆå¤±è´¥", state="error")
                st.error("æ— æ³•ç”Ÿæˆæœ‰æ•ˆå¤§çº²ï¼Œè¯·é‡è¯•ã€‚")
                st.session_state.processing = False
                st.stop()
            
            st.json(outline, expanded=False)
            
            # Step 3
            full_content = f"# {prompt}\n\n"
            prog_bar = st.progress(0)
            
            for i, section in enumerate(outline):
                status.write(f"âœï¸ æ­£åœ¨æ’°å†™: **{section['title']}**")
                result = agent.write_single_section(prompt, section, i+1)
                
                with st.expander(f"ğŸ‘ï¸ ç¬¬ {i+1} ç« æ‰§è¡Œç»†èŠ‚", expanded=True):
                    # æ˜¾ç¤ºä½¿ç”¨äº†å“ªäº›æœç´¢è¯
                    st.caption(f"ğŸ” æ„é€ çš„æœç´¢è¯: {', '.join(result.get('search_queries', []))}")
                    
                    if result.get('web_context'):
                        st.markdown("#### ğŸŒ äº’è”ç½‘æ£€ç´¢ç»“æœ")
                        for w in result['web_context']:
                            st.markdown(f"- [{w['title']}]({w['href']})")
                    else:
                        st.info("ğŸŒ æœªæ£€ç´¢åˆ°é«˜ç›¸å…³æ€§çš„äº’è”ç½‘å†…å®¹ï¼Œå°†åŸºäºé€šç”¨çŸ¥è¯†ç”Ÿæˆã€‚")
                        
                    if result.get('rag_context'):
                        st.markdown("#### ğŸ“‚ æœ¬åœ° RAG å¼•ç”¨")
                        for ctx in result['rag_context']:
                            st.caption(f"- {ctx[:100]}...")
                            
                    st.divider()
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        if result['image_path']:
                            st.image(result['image_path'])
                    with col2:
                        if result['image_path']:
                            st.success(f"é…å›¾æˆåŠŸ: {result['search_keyword']}")
                        else:
                            st.warning("é…å›¾å¤±è´¥")

                full_content += result['markdown']
                prog_bar.progress((i + 1) / len(outline))
            
            # Step 4
            status.write("ğŸ“„ ç”Ÿæˆæ–‡æ¡£...")
            md_path = os.path.join(task_dir, "final_article.md")
            docx_path = os.path.join(task_dir, "final_article.docx")
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(full_content)
            DocumentGenerator().convert_markdown_to_docx(full_content, docx_path)
            status.update(label="âœ… å®Œæˆï¼", state="complete")

        st.divider()
        tab1, tab2 = st.tabs(["ğŸ“– é˜…è¯»", "ğŸ’¾ ä¸‹è½½"])
        with tab1:
            render_article_preview(full_content, task_dir)
        with tab2:
            col1, col2 = st.columns(2)
            with col1:
                with open(docx_path, "rb") as f:
                    st.download_button("ä¸‹è½½ Word", f, file_name=f"{safe_topic}.docx")
            with col2:
                with open(md_path, "rb") as f:
                    st.download_button("ä¸‹è½½ Markdown", f, file_name=f"{safe_topic}.md")
        
        st.session_state.processing = False
        st.session_state.messages.append({"role": "assistant", "content": "ä»»åŠ¡å®Œæˆï¼"})
